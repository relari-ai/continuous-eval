---
title: Introduction
description: Overview
---

**To Improve after drafting Bookface Post**

## What is continuous-eval?

`continuous-eval` is an open-source package created for the scientific and practical evaluation of LLM application pipelines. Currently, it focuses on retrieval-augmented generation (RAG) pipelines.

## Why run evaluation?

Running evaluation can help accelerate your development. Without understanding the performance of your pipeline, it is difficult to know what and how to improve.

## Why use continuous eval?

- No need for LLMs
- Scientific
- Advanced tool for metric ensembling

## Resources

- **A Practical Guide to RAG Pipeline Evaluation:** [Part 1: Retrieval](https://medium.com/relari/a-practical-guide-to-rag-pipeline-evaluation-part-1-27a472b09893), [Part 2: Generation](https://medium.com/relari/a-practical-guide-to-rag-evaluation-part-2-generation-c79b1bde0f5d)
- Discord: Join our community of LLM developers [Discord](https://discord.gg/GJnM8SRsHr).
- Talk to founders: [email](founders@relari.ai)